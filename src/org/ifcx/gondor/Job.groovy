package org.ifcx.gondor

import org.ggf.drmaa.JobTemplate
import org.ifcx.drmaa.GondorJobTemplate

/**
 * Created with IntelliJ IDEA.
 * User: jim
 * Date: 2/22/14
 * Time: 9:48 PM
 * To change this template use File | Settings | File Templates.
 */

class Job {
    WorkflowImpl workflow
    String id
    String comment
    File templateFile
    File workingDir
    Integer procId
    Set<String> parentIds = []
    String preScript
    String preScriptArgs
    Set<Integer> preSkipCodes = []
    String postScript = preScript
    String postScriptArgs

    Job init(GondorJobTemplate jt) {
        def (jobTemplateName, jobComment, jobTemplateFile) = getJobTemplateFile(jt)
        id = nextJobId(jobTemplateName)
        comment = jobComment
        /*procId: -1,*/
        templateFile = jobTemplateFile
        parentIds.addAll(workflow.parentJobIds)
        this
    }

    void printToDAG(PrintWriter printer) {
        printer.println '# ' + comment
        printer.println "JOB ${id} ${templateFile.path}" + (workingDir ? ' DIR ' + workingDir.path : '')

        def vars = [:]

        if (procId != null) {
            vars._GONDOR_PROCID = procId
        }

        if (vars) {
            printer.println "VARS ${id} ${vars.collect { k, v -> "$k=\"$v\"" }.join(' ')}"
        }

        if (preScript) printer.println "SCRIPT PRE $id $preScript $preScriptArgs"

        preSkipCodes.each { printer.println "PRE_SKIP $id $it" }

        if (postScript) printer.println "SCRIPT POST $id $postScript $postScriptArgs"
    }

    String nextJobId(String jobName) {
        jobName + String.format("_%04d", workflow.nextJobNumber())
    }

    String nextJobTemplateName(String jobTemplateName) {
        String.format("${jobTemplateName}_%03d", workflow.nextJobTemplateNumber())
    }

    /**
     * Create a Condor submit file for the job template.
     *
     * @param jt a {@link JobTemplate}
     * @param number the number of times to execute the job
     * @see "condor_submit man page"
     * @return a {@link File} for the submit file created
     * @throws Exception
     */
    void writeJobTemplateFile(JobTemplate jt, File jobTemplateFile) throws Exception {
        jobTemplateFile.withPrintWriter { printer ->
            printer.println """### BEGIN Condor Job Template File ###
# Generated by ${workflow.drmSystem} version ${workflow.version} using ${workflow.drmaaImplementation}
#
Universe=vanilla
Executable=${jt.remoteCommand}
Log=${getLogFilePath()}
"""
            // Handle the case of the user/caller setting the environment for the job.
            if (jt.jobEnvironment) {
                // This is the Condor directive for setting the job environment.
                // See <http://research.cs.wisc.edu/htcondor/manual/v8.0/condor_submit.html#man-condor-submit-environment>.
                // We use the "new" format of course which involves escaping ' and " by repeating them and
                // surrounding spaces with a pair of single quotes.
                // Should check for/complain about sketchy variable names (suitable POSIX specs?).
                // That test is being done now in JobTemplateImpl.
                // Still kinda late since it doesn't fail as soon as the user's script gives us (Gondor) the bad value.
                List<String> envEntries = jt.jobEnvironment.collect { k, v -> "$k=$v" }
                printer.println "Environment=" + escapeForCondorSubmit(envEntries)
            }

            // Here we handle the job arguments, if any have been supplied.
            // We try to adhere to the "new" way of specifying the arguments
            // as explained in the 'condor_submit' man page.
            // <http://research.cs.wisc.edu/htcondor/manual/v8.0/condor_submit.html#man-condor-submit-arguments>
            if (jt.args) {
                printer.println "Arguments=" + escapeForCondorSubmit(jt.args)
            }

            // If the working directory has been set, configure it.
            if (jt.workingDirectory != null) {
                printer.println "InitialDir=" + formatPathForCondorSubmit(jt.workingDirectory)
            }

            // Handle any native specifications that have been set
            if (jt.getNativeSpecification() != null) {
                printer.println(jt.getNativeSpecification())
            }

            // Handle the job category.
            //TODO: Could use priority or rank for this.
            if (jt.getJobCategory() != null) {
                printer.println("# Category=" + jt.getJobCategory())
            }

            // If the caller has specified a start time, then we add special
            // Condor settings into the submit file. Otherwise, don't do anything
            // special...
            if (jt.getStartTime() != null) {
                long time = (jt.getStartTime().getTimeInMillis() + 500) / 1000;
                printer.println("PeriodicRelease=(CurrentTime > " + time + ")");

//                // TODO: Is this correct?  If we submit with a hold will release happen?
//                if (jt.getJobSubmissionState() != JobTemplate.HOLD_STATE) {
//                    writer.println "Hold=true"
//                }
            }

            // Handle the naming of the job.
            if (jt.jobName) {
                // TODO: The C implementation has a "+" character in front of the
                // directive. We add it here as well. Find out why (or if) this is necessary.
                printer.println("+JobName=" + jt.jobName);
            }

            // Handle the job input path. Care must be taken to replace DRMAA tokens
            // with tokens that Condor understands.
            if (jt.getInputPath() != null) {
                printer.println "Input=" + formatPathForCondorSubmit(jt.inputPath)

                // Check whether to transfer the input files
                if (jt.transferFiles?.inputStream) {
                    printer.println("transfer_input_files=" + formatPathForCondorSubmit(jt.inputPath));
                }
            }

            // Handle the job output path. Care must be taken to replace DRMAA tokens
            // with tokens that Condor understands.
            if (jt.outputPath) {
                printer.println("Output=" + formatPathForCondorSubmit(jt.outputPath));

                // Check if we need to join input and output files
                // FIXME: Condor manual sez this won't work.  Quite likely since this probably hasn't been tested.
                // Actually there is a test in the suite, so the story isn't clear here.
                if (jt.joinFiles) {
                    printer.println("# Joining Input and Output");
                    printer.println("Error=" + formatPathForCondorSubmit(jt.outputPath));
                }
            }

            // Handle the error path if specified. Do token replacement if necessary.
            if (! jt.joinFiles && jt.errorPath) {
                printer.println("Error=" + formatPathForCondorSubmit(jt.errorPath))
            }

            if (jt.transferFiles?.outputStream) {
                printer.println("should_transfer_files=IF_NEEDED");
                printer.println("when_to_transfer_output=ON_EXIT");
            }

            // Send email notifications?
            if (jt.getBlockEmail()) {
                printer.println("Notification=Never");
            }

            // Documentation is a bit thin, but it seems Condor will accept multiple
            // email addresses separated by a comma.
            Set<String> emails = []
            if (workflow.contact) emails.add(workflow.contact)
            if (jt.email) emails.addAll(jt.email)
            if (emails) {
                printer.println("Notify_user=" + escapeForCondorSubmit([emails.join(",")]))
            }

            // Should jobs be submitted into a holding pattern
            // (don't immediately start running them)?
            if (jt.getJobSubmissionState() == JobTemplate.HOLD_STATE) {
                printer.println "Hold=true"
            }

            // Every Condor submit file needs a Queue directive to make the job go.
            // Array jobs will have a Queue count greater than 1.
            printer.println "Queue"
            printer.println "#"
            printer.println "### END Condor Job Template File ###"
        }
    }

    //FIXME: Appears that Condor does not allow file paths to have spaces in them, even though this is spelled out anywhere.
    // A dodgy workaround is to specify the ClassAd variable directly like this:
    // +Out ="this dir name has spaces/env_dump3.txt"
    // But that is bound to have problems.  Plus there are things like the file transfer commands that expect
    // a list of file paths separated by spaces and/or commas.
    // The thing to do for now is probably to check for bad names and complain.
    // The docs do say this though:
    //          All path names specified in the submit description file must be less than 256 characters in length,
    //          and command line arguments must be less than 4096 characters in length; otherwise, condor_submit gives
    //          a warning message but the jobs will not execute properly.

    String formatPathForCondorSubmit(String path) { replacePathPlaceholders(path) }

    static String escapeForCondorSubmit(List<String> entries) {
        // The rules are:
        //      If the entry contains a single quote or space then the whole thing is enclosed in single
        // quotes and single quotes get doubled.
        //      All double quotes in entries are doubled.
        //      The entries are all separated by a space and the whole thing is enclosed in double quotes.
        '"' + entries.collect {
            (it.contains(" ") || it.contains("'")) ? "'" + it.replace("'", "''") + "'" : it
        }.join(" ").replace('"', '""') + '"'
    }

    private String replacePathPlaceholders(String path) {
        path = path.replace(JobTemplate.PARAMETRIC_INDEX, '$(_GONDOR_PROCID)')
        path = path.replace(JobTemplate.HOME_DIRECTORY, '$ENV(HOME)')
        path = path.replace(JobTemplate.WORKING_DIRECTORY, (workingDir ?: workflow.workingDir).path)
        if (path.startsWith(":")) {
            path = path.substring(1);
        }
        path
    }


    def getJobTemplateFile(JobTemplate jt0) {
//        if (jobTemplateMap.containsKey(jt0)) {
//            return jobTemplateFiles[jobTemplateMap[jt0]]
//        }
//
//        if (jobTemplateMap.values().find { it.jobName.equalsIgnoreCase(jt0.jobName) }) {
//            throw new InvalidJobTemplateException("Job name ${jt0.jobName} used in more than one job template but they are not equivalent.")
//        }
//
//        jt0 = (JobTemplateImpl) jt0.clone()
//        JobTemplate jt1 = (JobTemplateImpl) jt0.clone()

        def jt1 = jt0

        def jobTemplateName = nextJobTemplateName(jt1.jobName ?: defaultJobTemplateName(jt1.remoteCommand))

        File jobTemplateFile = new File(workflow.temporaryFilesDir, jobTemplateName + ".job")

        writeJobTemplateFile(jt1, jobTemplateFile)

//        jobTemplateMap[jt0] = jt1
//        jobTemplateFiles[jt1] = jobTemplateFile

        def jobComment = "${jt1.workingDirectory ? 'cd ' + replacePathPlaceholders(jt1.workingDirectory) + ' ' : ''}" +
                "${jt1.remoteCommand} ${jt1.args.join(' ')}" +
                "${jt1.inputPath ? ' <' + replacePathPlaceholders(jt1.inputPath) : ''}" +
                "${jt1.outputPath ? ' >' + replacePathPlaceholders(jt1.outputPath) : ''}" +
                "${jt1.errorPath ? ' 2>' + replacePathPlaceholders(jt1.errorPath) : ''}"

        [jobTemplateName, jobComment, jobTemplateFile]
    }

    String getLogFilePath() {
        workflow.getLogFilePath()
    }

    static String defaultJobTemplateName(String path) {
        def name = path.replaceAll(/[^A-Za-z_]/, '_')
        if (!name.startsWith('_')) name = '_' + name
        name
    }
}
